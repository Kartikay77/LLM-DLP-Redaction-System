{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rLK393b0CUg",
        "outputId": "59a1185a-95a1-4c33-9678-a6ff81cd22a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Exists? True\n",
            "['checkpoint-1126',\n",
            " 'checkpoint-1689',\n",
            " 'config.json',\n",
            " 'model.safetensors',\n",
            " 'special_tokens_map.json',\n",
            " 'vocab.txt',\n",
            " 'training_args.bin',\n",
            " 'tokenizer_config.json',\n",
            " 'tokenizer.json',\n",
            " 'labels.json']\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, pprint\n",
        "PROJECT_DIR = \"/content/drive/MyDrive/DataShield_AI\"\n",
        "MODEL_DIR   = f\"{PROJECT_DIR}/models/ner-distilbert\"\n",
        "\n",
        "print(\"Exists?\", os.path.isdir(MODEL_DIR))\n",
        "pprint.pp(os.listdir(MODEL_DIR))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HF_HUB_OFFLINE\"] = \"1\"\n",
        "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\""
      ],
      "metadata": {
        "id": "x73OK7sU222x"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForTokenClassification\n",
        "from transformers import TokenClassificationPipeline\n",
        "\n",
        "# Load tokenizer & model from local folder only\n",
        "tok = DistilBertTokenizerFast.from_pretrained(MODEL_DIR, local_files_only=True)\n",
        "mdl = DistilBertForTokenClassification.from_pretrained(MODEL_DIR, local_files_only=True)\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "ner = TokenClassificationPipeline(\n",
        "    model=mdl, tokenizer=tok, aggregation_strategy=\"simple\", device=device\n",
        ")\n",
        "\n",
        "text = \"My SSN is 123-45-6789 and email is john@example.com\"\n",
        "ner(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9DkNl9h3DFc",
        "outputId": "8827145f-b1f1-49e8-9c7b-d505bba35750"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PERSON',\n",
              "  'score': np.float32(0.7593688),\n",
              "  'word': 'My',\n",
              "  'start': 0,\n",
              "  'end': 2},\n",
              " {'entity_group': 'PERSON',\n",
              "  'score': np.float32(0.9343675),\n",
              "  'word': 'SSN',\n",
              "  'start': 3,\n",
              "  'end': 6},\n",
              " {'entity_group': 'PHONE',\n",
              "  'score': np.float32(0.9995421),\n",
              "  'word': '123 - 45 - 6789',\n",
              "  'start': 10,\n",
              "  'end': 21},\n",
              " {'entity_group': 'EMAIL',\n",
              "  'score': np.float32(0.99941206),\n",
              "  'word': 'j',\n",
              "  'start': 35,\n",
              "  'end': 36},\n",
              " {'entity_group': 'EMAIL',\n",
              "  'score': np.float32(0.9958656),\n",
              "  'word': '##oh',\n",
              "  'start': 36,\n",
              "  'end': 38},\n",
              " {'entity_group': 'EMAIL',\n",
              "  'score': np.float32(0.9260991),\n",
              "  'word': '##n @ example. com',\n",
              "  'start': 38,\n",
              "  'end': 51}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, pprint\n",
        "PROJECT_DIR = \"/content/drive/MyDrive/DataShield_AI\"\n",
        "MODEL_DIR   = f\"{PROJECT_DIR}/models/ner-distilbert\"\n",
        "\n",
        "print(\"Exists?\", os.path.isdir(MODEL_DIR))\n",
        "pprint.pp(os.listdir(MODEL_DIR))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TQSpWwr2F05",
        "outputId": "010181d2-8579-4ef7-bf06-4115fbf36c84"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Exists? True\n",
            "['checkpoint-1126',\n",
            " 'checkpoint-1689',\n",
            " 'config.json',\n",
            " 'model.safetensors',\n",
            " 'special_tokens_map.json',\n",
            " 'vocab.txt',\n",
            " 'training_args.bin',\n",
            " 'tokenizer_config.json',\n",
            " 'tokenizer.json',\n",
            " 'labels.json']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, subprocess, pkgutil\n",
        "def pipi(cmd): subprocess.check_call([sys.executable, \"-m\", \"pip\"] + cmd.split())\n",
        "\n",
        "# Show current versions\n",
        "import importlib, pkg_resources\n",
        "for p in [\"transformers\",\"huggingface_hub\",\"tokenizers\"]:\n",
        "    try:\n",
        "        m = importlib.import_module(p)\n",
        "        print(p, \"→\", m.__version__)\n",
        "    except:\n",
        "        print(p, \"not installed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKqmPoO12ORY",
        "outputId": "b36d06f0-6cdc-489d-bd08-b07fdb761cb8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers → 4.57.1\n",
            "huggingface_hub → 0.36.0\n",
            "tokenizers → 0.22.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GttcZ0lF2OUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FzHzhWCi2OW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RE_EMAIL = re.compile(r'\\b[a-zA-Z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b')\n",
        "RE_PHONE = re.compile(r'\\b(?:\\+?\\d{1,3}[\\s-]?)?(?:\\(?\\d{3}\\)?[\\s-]?)?\\d{3}[\\s-]?\\d{4}\\b')\n",
        "RE_SSN   = re.compile(r'\\b\\d{3}-\\d{2}-\\d{4}\\b')\n",
        "RE_CC    = re.compile(r'\\b(?:\\d[ -]*?){13,19}\\b')\n",
        "\n",
        "SEVERITY = {\"SSN\":\"HIGH\",\"CREDITCARD\":\"HIGH\",\"APIKEY\":\"HIGH\",\n",
        "            \"EMAIL\":\"MEDIUM\",\"PHONE\":\"MEDIUM\",\"ADDRESS\":\"MEDIUM\",\"PERSON\":\"LOW\"}\n",
        "\n",
        "def normalize_email(s):\n",
        "    s = re.sub(r'\\s*@\\s*', '@', s)\n",
        "    s = re.sub(r'\\s*\\.\\s*', '.', s)\n",
        "    return s\n",
        "\n",
        "def span_overlap(a, b):\n",
        "    return not (a[1] <= b[0] or b[1] <= a[0])"
      ],
      "metadata": {
        "id": "YvgAA-kd0G3z"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ner_entities(text):\n",
        "    out = []\n",
        "    for r in ner(text):\n",
        "        s,e = r[\"start\"], r[\"end\"]\n",
        "        lab = r[\"entity_group\"]\n",
        "        chunk = text[s:e]\n",
        "        if lab == \"EMAIL\": chunk = normalize_email(chunk)\n",
        "        out.append({\"start\": s, \"end\": e, \"label\": lab, \"score\": float(r[\"score\"]), \"source\": \"NER\"})\n",
        "    return out\n",
        "\n",
        "def rule_entities(text):\n",
        "    spans = []\n",
        "    for m in RE_SSN.finditer(text):\n",
        "        spans.append({\"start\": m.start(), \"end\": m.end(), \"label\":\"SSN\", \"score\":1.0, \"source\":\"RULE\"})\n",
        "    for m in RE_CC.finditer(text):\n",
        "        spans.append({\"start\": m.start(), \"end\": m.end(), \"label\":\"CREDITCARD\", \"score\":1.0, \"source\":\"RULE\"})\n",
        "    for m in RE_EMAIL.finditer(text):\n",
        "        spans.append({\"start\": m.start(), \"end\": m.end(), \"label\":\"EMAIL\", \"score\":1.0, \"source\":\"RULE\"})\n",
        "    for m in RE_PHONE.finditer(text):\n",
        "        spans.append({\"start\": m.start(), \"end\": m.end(), \"label\":\"PHONE\", \"score\":1.0, \"source\":\"RULE\"})\n",
        "    return spans\n",
        "\n",
        "PRIORITY = {\"RULE\": 2, \"NER\": 1}\n",
        "\n",
        "def resolve_overlaps(spans):\n",
        "    def key(sp):\n",
        "        sev = {\"HIGH\":3,\"MEDIUM\":2,\"LOW\":1}[SEVERITY.get(sp[\"label\"], \"LOW\")]\n",
        "        return (PRIORITY.get(sp[\"source\"],0), sev, sp[\"score\"], sp[\"end\"]-sp[\"start\"])\n",
        "    spans = sorted(spans, key=key, reverse=True)\n",
        "    kept = []\n",
        "    for sp in spans:\n",
        "        if all(not span_overlap((sp[\"start\"], sp[\"end\"]), (k[\"start\"], k[\"end\"])) for k in kept):\n",
        "            kept.append(sp)\n",
        "    return sorted(kept, key=lambda x: x[\"start\"])"
      ],
      "metadata": {
        "id": "iY-_jCrL0G6a"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def redact_text(text, spans, style=\"stars\"):\n",
        "    chars = list(text)\n",
        "    for sp in spans:\n",
        "        s,e,lab = sp[\"start\"], sp[\"end\"], sp[\"label\"]\n",
        "        if style == \"stars\":\n",
        "            chars[s:e] = \"*\" * (e - s)\n",
        "        elif style == \"label\":\n",
        "            chars[s:e] = f\"[{lab}_REDACTED]\"\n",
        "        elif style == \"partial_email\" and lab == \"EMAIL\":\n",
        "            chunk = normalize_email(text[s:e])\n",
        "            try:\n",
        "                user, domain = chunk.split(\"@\",1)\n",
        "                masked = f\"{user[:1]}***@{domain}\"\n",
        "            except Exception:\n",
        "                masked = \"***\"\n",
        "            chars[s:e] = masked\n",
        "        else:\n",
        "            chars[s:e] = \"***\"\n",
        "    return \"\".join(chars)\n",
        "\n",
        "def coaching_message(findings):\n",
        "    high = any(f[\"severity\"]==\"HIGH\" for f in findings)\n",
        "    kinds = sorted({f[\"label\"] for f in findings})\n",
        "    if high:\n",
        "        return f\"High-severity data detected ({', '.join(kinds)}). Keys/SSNs must be rotated or invalidated immediately. Do not paste secrets in chat/email.\"\n",
        "    if kinds:\n",
        "        return f\"Detected {', '.join(kinds)}. Consider sharing via a secure vault and avoid plaintext.\"\n",
        "    return \"No sensitive data detected.\"\n",
        "\n",
        "def detect_and_redact(text):\n",
        "    spans = resolve_overlaps(ner_entities(text) + rule_entities(text))\n",
        "    redacted = redact_text(text, spans, style=\"stars\")\n",
        "    findings = [{\n",
        "        \"label\": sp[\"label\"],\n",
        "        \"severity\": SEVERITY.get(sp[\"label\"], \"LOW\"),\n",
        "        \"span\": [sp[\"start\"], sp[\"end\"]],\n",
        "        \"source\": sp[\"source\"]\n",
        "    } for sp in spans]\n",
        "    advice = coaching_message(findings)\n",
        "    event = {\n",
        "        \"id\": str(uuid.uuid4()),\n",
        "        \"original_text\": text,\n",
        "        \"redacted_text\": redacted,\n",
        "        \"findings\": findings,\n",
        "        \"advice\": advice,\n",
        "        \"ts\": time.time()\n",
        "    }\n",
        "    return event"
      ],
      "metadata": {
        "id": "7TlHzo-w0G9S"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = \"Email me at alice.lee @ example . com or call 415-555-1234. My SSN is 123-45-6789.\"\n",
        "event = detect_and_redact(sample)\n",
        "event[\"redacted_text\"], event[\"findings\"], event[\"advice\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GeheYts0G_u",
        "outputId": "2de7350f-780a-46b3-cb84-83e8f10e6b5b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Email ** at ************************* or call ************. ** *** is ***********.',\n",
              " [{'label': 'EMAIL', 'severity': 'MEDIUM', 'span': [6, 8], 'source': 'NER'},\n",
              "  {'label': 'EMAIL', 'severity': 'MEDIUM', 'span': [12, 14], 'source': 'NER'},\n",
              "  {'label': 'EMAIL', 'severity': 'MEDIUM', 'span': [14, 18], 'source': 'NER'},\n",
              "  {'label': 'EMAIL', 'severity': 'MEDIUM', 'span': [18, 20], 'source': 'NER'},\n",
              "  {'label': 'EMAIL', 'severity': 'MEDIUM', 'span': [20, 37], 'source': 'NER'},\n",
              "  {'label': 'PHONE', 'severity': 'MEDIUM', 'span': [46, 58], 'source': 'RULE'},\n",
              "  {'label': 'PERSON', 'severity': 'LOW', 'span': [60, 62], 'source': 'NER'},\n",
              "  {'label': 'PERSON', 'severity': 'LOW', 'span': [63, 66], 'source': 'NER'},\n",
              "  {'label': 'SSN', 'severity': 'HIGH', 'span': [70, 81], 'source': 'RULE'}],\n",
              " 'High-severity data detected (EMAIL, PERSON, PHONE, SSN). Keys/SSNs must be rotated or invalidated immediately. Do not paste secrets in chat/email.')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LOG_PATH = f\"{PROJECT_DIR}/logs/audit.jsonl\"\n",
        "import os, json\n",
        "os.makedirs(f\"{PROJECT_DIR}/logs\", exist_ok=True)\n",
        "\n",
        "def stream_demo(chunks):\n",
        "    for ch in chunks:\n",
        "        ev = detect_and_redact(ch)\n",
        "        print(\"IN :\", ch)\n",
        "        print(\"OUT:\", ev[\"redacted_text\"])\n",
        "        print(\"FND:\", ev[\"findings\"])\n",
        "        print(\"ADVICE:\", ev[\"advice\"])\n",
        "        with open(LOG_PATH, \"a\") as f:\n",
        "            f.write(json.dumps(ev) + \"\\n\")\n",
        "        time.sleep(0.2)\n",
        "\n",
        "chunks = [\n",
        "  \"Here is my email: john.doe @ gmail . com\",\n",
        "  \"Temp API key: sk_live_1234567890abcdef\",\n",
        "  \"Use 4242-4242-4242-4242 for tests; SSN 123-45-6789 should be blocked.\"\n",
        "]\n",
        "stream_demo(chunks)\n",
        "\n",
        "print(\"Audit log →\", LOG_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hXwTx0Y0HCE",
        "outputId": "bb0211ba-5e69-43fa-aa13-8ba416b8f546"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IN : Here is my email: john.doe @ gmail . com\n",
            "OUT: Here is my email: **********************\n",
            "FND: [{'label': 'EMAIL', 'severity': 'MEDIUM', 'span': [18, 19], 'source': 'NER'}, {'label': 'EMAIL', 'severity': 'MEDIUM', 'span': [19, 21], 'source': 'NER'}, {'label': 'EMAIL', 'severity': 'MEDIUM', 'span': [21, 23], 'source': 'NER'}, {'label': 'EMAIL', 'severity': 'MEDIUM', 'span': [23, 25], 'source': 'NER'}, {'label': 'EMAIL', 'severity': 'MEDIUM', 'span': [25, 40], 'source': 'NER'}]\n",
            "ADVICE: Detected EMAIL. Consider sharing via a secure vault and avoid plaintext.\n",
            "IN : Temp API key: sk_live_1234567890abcdef\n",
            "OUT: Temp *** key: ***********************f\n",
            "FND: [{'label': 'PERSON', 'severity': 'LOW', 'span': [5, 8], 'source': 'NER'}, {'label': 'APIKEY', 'severity': 'HIGH', 'span': [14, 15], 'source': 'NER'}, {'label': 'APIKEY', 'severity': 'HIGH', 'span': [15, 16], 'source': 'NER'}, {'label': 'EMAIL', 'severity': 'MEDIUM', 'span': [16, 17], 'source': 'NER'}, {'label': 'APIKEY', 'severity': 'HIGH', 'span': [17, 21], 'source': 'NER'}, {'label': 'APIKEY', 'severity': 'HIGH', 'span': [21, 22], 'source': 'NER'}, {'label': 'APIKEY', 'severity': 'HIGH', 'span': [22, 37], 'source': 'NER'}]\n",
            "ADVICE: High-severity data detected (APIKEY, EMAIL, PERSON). Keys/SSNs must be rotated or invalidated immediately. Do not paste secrets in chat/email.\n",
            "IN : Use 4242-4242-4242-4242 for tests; SSN 123-45-6789 should be blocked.\n",
            "OUT: Use ******************* for tests; SS* *********** should be blocked.\n",
            "FND: [{'label': 'CREDITCARD', 'severity': 'HIGH', 'span': [4, 23], 'source': 'RULE'}, {'label': 'PHONE', 'severity': 'MEDIUM', 'span': [37, 38], 'source': 'NER'}, {'label': 'SSN', 'severity': 'HIGH', 'span': [39, 50], 'source': 'RULE'}]\n",
            "ADVICE: High-severity data detected (CREDITCARD, PHONE, SSN). Keys/SSNs must be rotated or invalidated immediately. Do not paste secrets in chat/email.\n",
            "Audit log → /content/drive/MyDrive/DataShield_AI/logs/audit.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re, time, uuid, json\n",
        "from typing import List, Dict\n",
        "\n",
        "# --- High-precision rules ---\n",
        "RE_EMAIL = re.compile(r'\\b[a-zA-Z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b')\n",
        "RE_PHONE = re.compile(r'\\b(?:\\+?\\d{1,3}[\\s\\-]?)?(?:\\(?\\d{3}\\)?[\\s\\-]?)?\\d{3}[\\s\\-]?\\d{4}\\b')\n",
        "RE_SSN   = re.compile(r'\\b\\d{3}-\\d{2}-\\d{4}\\b')\n",
        "RE_CC    = re.compile(r'\\b(?:\\d[ -]?){13,19}\\b')\n",
        "\n",
        "# Common API key shapes (very conservative demo patterns)\n",
        "RE_APIKEY = re.compile(\n",
        "    r'\\b(?:sk_(?:live|test)_[A-Za-z0-9]{16,}|'\n",
        "    r'AIza[0-9A-Za-z\\-_]{35}|'\n",
        "    r'(?:ghp|gitpat)_[A-Za-z0-9]{30,}|'\n",
        "    r'AKIA[0-9A-Z]{16})\\b'\n",
        ")\n",
        "\n",
        "SEVERITY = {\n",
        "    \"SSN\":\"HIGH\",\"CREDITCARD\":\"HIGH\",\"APIKEY\":\"HIGH\",\n",
        "    \"EMAIL\":\"MEDIUM\",\"PHONE\":\"MEDIUM\",\"ADDRESS\":\"MEDIUM\",\"PERSON\":\"LOW\"\n",
        "}\n",
        "PRIORITY = {\"RULE\": 2, \"NER\": 1}\n",
        "\n",
        "STOPWORD_PERSON = {\"my\", \"the\", \"a\", \"an\", \"this\", \"that\", \"here\", \"there\", \"it\"}  # tiny noise filter\n",
        "\n",
        "def normalize_email(s:str)->str:\n",
        "    s = re.sub(r'\\s*@\\s*', '@', s)\n",
        "    s = re.sub(r'\\s*\\.\\s*', '.', s)\n",
        "    return s\n",
        "\n",
        "def span_overlap(a, b):\n",
        "    return not (a[1] <= b[0] or b[1] <= a[0])\n",
        "\n",
        "def merge_adjacent(text:str, ents:List[Dict], join_gap:int=1)->List[Dict]:\n",
        "    \"\"\"Merge adjacent same-type spans (fix WordPiece splits).\"\"\"\n",
        "    if not ents: return []\n",
        "    ents = sorted(ents, key=lambda x: x[\"start\"])\n",
        "    out = [ents[0].copy()]\n",
        "    for e in ents[1:]:\n",
        "        last = out[-1]\n",
        "        same = e[\"label\"] == last[\"label\"]\n",
        "        touching = e[\"start\"] <= last[\"end\"] + join_gap\n",
        "        if same and touching:\n",
        "            last[\"end\"] = max(last[\"end\"], e[\"end\"])\n",
        "            last[\"score\"] = max(float(last.get(\"score\",1.0)), float(e.get(\"score\",1.0)))\n",
        "            last[\"text\"] = text[last[\"start\"]:last[\"end\"]]\n",
        "        else:\n",
        "            e2 = e.copy()\n",
        "            e2[\"text\"] = text[e2[\"start\"]:e2[\"end\"]]\n",
        "            out.append(e2)\n",
        "    # normalize/clean\n",
        "    for sp in out:\n",
        "        if sp[\"label\"] == \"EMAIL\":\n",
        "            sp[\"text\"] = normalize_email(sp[\"text\"])\n",
        "    return out\n",
        "\n",
        "def ner_entities(text:str)->List[Dict]:\n",
        "    raw = ner(text)\n",
        "    ents = []\n",
        "    for r in raw:\n",
        "        s, e = int(r[\"start\"]), int(r[\"end\"])\n",
        "        lab  = r[\"entity_group\"]\n",
        "        tok  = text[s:e]\n",
        "        # tiny PERSON de-noiser\n",
        "        if lab == \"PERSON\" and tok.lower() in STOPWORD_PERSON:\n",
        "            continue\n",
        "        ents.append({\"start\": s, \"end\": e, \"label\": lab, \"score\": float(r[\"score\"]), \"source\": \"NER\", \"text\": tok})\n",
        "    return merge_adjacent(text, ents, join_gap=1)\n",
        "\n",
        "def rule_entities(text:str)->List[Dict]:\n",
        "    spans = []\n",
        "    for m in RE_SSN.finditer(text):\n",
        "        spans.append({\"start\": m.start(), \"end\": m.end(), \"label\":\"SSN\", \"score\":1.0, \"source\":\"RULE\", \"text\": m.group(0)})\n",
        "    for m in RE_CC.finditer(text):\n",
        "        spans.append({\"start\": m.start(), \"end\": m.end(), \"label\":\"CREDITCARD\", \"score\":1.0, \"source\":\"RULE\", \"text\": m.group(0)})\n",
        "    for m in RE_EMAIL.finditer(text):\n",
        "        spans.append({\"start\": m.start(), \"end\": m.end(), \"label\":\"EMAIL\", \"score\":1.0, \"source\":\"RULE\", \"text\": normalize_email(m.group(0))})\n",
        "    for m in RE_PHONE.finditer(text):\n",
        "        spans.append({\"start\": m.start(), \"end\": m.end(), \"label\":\"PHONE\", \"score\":1.0, \"source\":\"RULE\", \"text\": m.group(0)})\n",
        "    for m in RE_APIKEY.finditer(text):\n",
        "        spans.append({\"start\": m.start(), \"end\": m.end(), \"label\":\"APIKEY\", \"score\":1.0, \"source\":\"RULE\", \"text\": m.group(0)})\n",
        "    return spans\n",
        "\n",
        "def resolve_overlaps(spans:List[Dict])->List[Dict]:\n",
        "    def key(sp):\n",
        "        sev = {\"HIGH\":3,\"MEDIUM\":2,\"LOW\":1}[SEVERITY.get(sp[\"label\"], \"LOW\")]\n",
        "        return (PRIORITY.get(sp[\"source\"],0), sev, sp.get(\"score\",1.0), sp[\"end\"]-sp[\"start\"])\n",
        "    spans = sorted(spans, key=key, reverse=True)\n",
        "    kept = []\n",
        "    for sp in spans:\n",
        "        if all(not span_overlap((sp[\"start\"], sp[\"end\"]), (k[\"start\"], k[\"end\"])) for k in kept):\n",
        "            kept.append(sp)\n",
        "    return sorted(kept, key=lambda x: x[\"start\"])\n",
        "\n",
        "def redact_text(text:str, spans:List[Dict], style=\"stars\")->str:\n",
        "    \"\"\"Apply redaction; ensures no trailing chars leak.\"\"\"\n",
        "    chars = list(text)\n",
        "    for sp in spans:\n",
        "        s, e, lab = sp[\"start\"], sp[\"end\"], sp[\"label\"]\n",
        "        red = \"*\" * (e - s) if style==\"stars\" else f\"[{lab}_REDACTED]\"\n",
        "        # replace exactly s:e\n",
        "        chars[s:e] = list(red)\n",
        "    return \"\".join(chars)\n",
        "\n",
        "def coaching_message(findings):\n",
        "    high = any(SEVERITY.get(f[\"label\"],\"LOW\")==\"HIGH\" for f in findings)\n",
        "    kinds = sorted({f[\"label\"] for f in findings})\n",
        "    if high:\n",
        "        return f\"High-severity data detected ({', '.join(kinds)}). Rotate keys / invalidate SSNs immediately. Avoid sharing secrets in plaintext.\"\n",
        "    if kinds:\n",
        "        return f\"Detected {', '.join(kinds)}. Use a secrets vault and minimize plaintext sharing.\"\n",
        "    return \"No sensitive data detected.\"\n",
        "\n",
        "def detect_and_redact(text:str)->Dict:\n",
        "    spans = resolve_overlaps(ner_entities(text) + rule_entities(text))\n",
        "    redacted = redact_text(text, spans, style=\"stars\")\n",
        "    findings = [{\n",
        "        \"label\": sp[\"label\"],\n",
        "        \"severity\": SEVERITY.get(sp[\"label\"], \"LOW\"),\n",
        "        \"span\": [sp[\"start\"], sp[\"end\"]],\n",
        "        \"source\": sp[\"source\"],\n",
        "        \"text\": sp.get(\"text\",\"\")\n",
        "    } for sp in spans]\n",
        "    return {\n",
        "        \"id\": str(uuid.uuid4()),\n",
        "        \"original_text\": text,\n",
        "        \"redacted_text\": redacted,\n",
        "        \"findings\": findings,\n",
        "        \"advice\": coaching_message(findings),\n",
        "        \"ts\": time.time()\n",
        "    }"
      ],
      "metadata": {
        "id": "gQ88cS5545nc"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def benchmark_inference(sample, runs=50):\n",
        "    start = time.time()\n",
        "    for _ in range(runs):\n",
        "        _ = ner(sample)\n",
        "    end = time.time()\n",
        "    t = (end - start) / runs\n",
        "    print(f\"Avg latency: {t*1000:.2f} ms per request | {1/t:.2f} req/sec\")"
      ],
      "metadata": {
        "id": "fdinEOK0Okb6"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_inference(\"User email is john.doe@example.com and card 4444 3333 2222 1111\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lqVODu1Om7t",
        "outputId": "a76cb653-ba7a-49c9-8a28-01d57d4e54b7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg latency: 98.36 ms per request | 10.17 req/sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples = [\n",
        "  \"Email me at alice.lee @ example . com or call 415-555-1234. My SSN is 123-45-6789.\",\n",
        "  \"Temp API key: sk_live_1234567890abcdef\",\n",
        "  \"Use 4242-4242-4242-4242 for tests; SSN 123-45-6789 should be blocked.\"\n",
        "]\n",
        "for s in samples:\n",
        "    ev = detect_and_redact(s)\n",
        "    print(\"IN :\", s)\n",
        "    print(\"OUT:\", ev[\"redacted_text\"])\n",
        "    print(\"FND:\", ev[\"findings\"])\n",
        "    print(\"ADVICE:\", ev[\"advice\"])\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QAUwEu348d4",
        "outputId": "7461b266-8869-45af-84f6-80758eec1328"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IN : Email me at alice.lee @ example . com or call 415-555-1234. My SSN is 123-45-6789.\n",
            "OUT: Email ** at ************************* or call ************. My *** is ***********.\n",
            "FND: [{'label': 'EMAIL', 'severity': 'MEDIUM', 'span': [6, 8], 'source': 'NER', 'text': 'me'}, {'label': 'EMAIL', 'severity': 'MEDIUM', 'span': [12, 37], 'source': 'NER', 'text': 'alice.lee@example.com'}, {'label': 'PHONE', 'severity': 'MEDIUM', 'span': [46, 58], 'source': 'RULE', 'text': '415-555-1234'}, {'label': 'PERSON', 'severity': 'LOW', 'span': [63, 66], 'source': 'NER', 'text': 'SSN'}, {'label': 'SSN', 'severity': 'HIGH', 'span': [70, 81], 'source': 'RULE', 'text': '123-45-6789'}]\n",
            "ADVICE: High-severity data detected (EMAIL, PERSON, PHONE, SSN). Rotate keys / invalidate SSNs immediately. Avoid sharing secrets in plaintext.\n",
            "---\n",
            "IN : Temp API key: sk_live_1234567890abcdef\n",
            "OUT: Temp *** key: ************************\n",
            "FND: [{'label': 'PERSON', 'severity': 'LOW', 'span': [5, 8], 'source': 'NER', 'text': 'API'}, {'label': 'APIKEY', 'severity': 'HIGH', 'span': [14, 38], 'source': 'RULE', 'text': 'sk_live_1234567890abcdef'}]\n",
            "ADVICE: High-severity data detected (APIKEY, PERSON). Rotate keys / invalidate SSNs immediately. Avoid sharing secrets in plaintext.\n",
            "---\n",
            "IN : Use 4242-4242-4242-4242 for tests; SSN 123-45-6789 should be blocked.\n",
            "OUT: Use ********************for tests; SSN *********** should be blocked.\n",
            "FND: [{'label': 'CREDITCARD', 'severity': 'HIGH', 'span': [4, 24], 'source': 'RULE', 'text': '4242-4242-4242-4242 '}, {'label': 'SSN', 'severity': 'HIGH', 'span': [39, 50], 'source': 'RULE', 'text': '123-45-6789'}]\n",
            "ADVICE: High-severity data detected (CREDITCARD, SSN). Rotate keys / invalidate SSNs immediately. Avoid sharing secrets in plaintext.\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def coaching_agent(entities):\n",
        "    tips = []\n",
        "    for e in entities:\n",
        "        if \"CREDITCARD\" in e[\"entity_group\"]:\n",
        "            tips.append(\"Never paste credit card numbers in chat tools.\")\n",
        "        if \"SSN\" in e[\"entity_group\"]:\n",
        "            tips.append(\"SSNs should be handled only in secure HR systems.\")\n",
        "        if \"APIKEY\" in e[\"entity_group\"]:\n",
        "            tips.append(\"API keys belong in secrets managers, not messages.\")\n",
        "    return \"\\n\".join(tips)"
      ],
      "metadata": {
        "id": "JAVkCxdJO0Zt"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = ner(sample)\n",
        "# print(redact_output(sample, pred))\n",
        "print(coaching_agent(pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx2KgM7GO4kA",
        "outputId": "a8653eb5-bd93-4798-8597-13ac2b671e7e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEVERITY = {\n",
        "    \"APIKEY\": 10,\n",
        "    \"SSN\": 9,\n",
        "    \"CREDITCARD\": 8,\n",
        "    \"EMAIL\": 5,\n",
        "    \"PHONE\": 4,\n",
        "    \"ADDRESS\": 3,\n",
        "    \"PERSON\": 2\n",
        "}\n",
        "\n",
        "def severity_score(preds):\n",
        "    return sum(SEVERITY.get(p[\"entity_group\"].split(\"-\")[-1],0) for p in preds)"
      ],
      "metadata": {
        "id": "59KLPuifO-qH"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = severity_score(pred)\n",
        "print(\"Risk score:\", score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y-Ca6tiPBGI",
        "outputId": "d5318f88-e087-492b-8b53-59a6dff76e3f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Risk score: 37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_infer(text, retries=3):\n",
        "    for i in range(retries):\n",
        "        try:\n",
        "            return ner(text)\n",
        "        except Exception as e:\n",
        "            if i == retries-1:\n",
        "                raise e\n",
        "            time.sleep(0.1)"
      ],
      "metadata": {
        "id": "d2ZTRMKtPNkQ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_infer(texts):\n",
        "    return ner(texts, batch_size=8, truncation=True)"
      ],
      "metadata": {
        "id": "wkQy6Fg7PRZM"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForTokenClassification, TokenClassificationPipeline\n",
        "\n",
        "POLICIES = {\n",
        "    \"EMAIL\":      lambda x: re.sub(r\"(.{2}).*@(.+)\", r\"\\1***@\\2\", x),\n",
        "    \"PHONE\":      lambda x: \"***-***-\" + re.sub(r\"\\D\", \"\", x)[-4:],\n",
        "    \"CREDITCARD\": lambda x: \"**** **** **** \" + re.sub(r\"\\D\", \"\", x)[-4:],\n",
        "    \"SSN\":        lambda x: \"***-**-\" + x[-4:],\n",
        "    \"APIKEY\":     lambda x: \"[REDACTED-API]\",\n",
        "    \"PERSON\":     lambda x: \"[PERSON]\",\n",
        "    \"ADDRESS\":    lambda x: \"[ADDRESS]\"\n",
        "}\n",
        "\n",
        "def apply_policy(entity_group, token):\n",
        "    base = entity_group.replace(\"B-\",\"\").replace(\"I-\",\"\")\n",
        "    func = POLICIES.get(base, lambda x: x)\n",
        "    return func(token)\n",
        "\n",
        "# ---------- Rule-based pre-pass (fallbacks NER might miss) ----------\n",
        "_RULES = [\n",
        "    # Emails (tolerate spaces around @ and .)\n",
        "    (re.compile(r'([A-Za-z0-9._%+-]{2})[A-Za-z0-9._%+-]*\\s*@\\s*([A-Za-z0-9.-]+(?:\\s*\\.\\s*[A-Za-z]{2,})+)'),\n",
        "     lambda m: f\"{m.group(1)}***@{re.sub(r'\\\\s*\\\\.\\\\s*', '.', m.group(2).replace(' ', ''))}\"),\n",
        "    # SSN\n",
        "    (re.compile(r'\\b\\d{3}-\\d{2}-\\d{4}\\b'), lambda m: \"***-**-\" + m.group(0)[-4:]),\n",
        "    # Credit cards (13–16 digits with spaces/dashes)\n",
        "    (re.compile(r'\\b(?:\\d[ -]*?){13,16}\\b'), lambda m: \"**** **** **** \" + re.sub(r'\\D','', m.group(0))[-4:]),\n",
        "    # US phones\n",
        "    (re.compile(r'\\b(?:\\+?\\d{1,3}[-.\\s]?)?(?:\\(?\\d{3}\\)?[-.\\s]?){2}\\d{4}\\b'),\n",
        "     lambda m: \"***-***-\" + re.sub(r'\\D','', m.group(0))[-4:]),\n",
        "    # Stripe-like API keys\n",
        "    (re.compile(r'\\bsk_(?:live|test)_[A-Za-z0-9]{16,}\\b'), lambda m: \"[REDACTED-API]\"),\n",
        "]\n",
        "\n",
        "def rule_based_redact(text: str) -> str:\n",
        "    out = text\n",
        "    for pat, repl in _RULES:\n",
        "        out = pat.sub(repl, out)\n",
        "    return out\n",
        "\n",
        "# ---------- Span-safe NER redaction ----------\n",
        "def redact_output(text, ner_preds):\n",
        "    out = rule_based_redact(text)\n",
        "\n",
        "    # Collect spans (start, end, label), drop obvious junk\n",
        "    spans = []\n",
        "    for p in ner_preds:\n",
        "        s, e = int(p[\"start\"]), int(p[\"end\"])\n",
        "        if 0 <= s < e <= len(text):\n",
        "            spans.append((s, e, p[\"entity_group\"]))\n",
        "\n",
        "    # Apply right-to-left to avoid index shift; also skip if policy returns identical string\n",
        "    for s, e, label in sorted(spans, key=lambda t: t[0], reverse=True):\n",
        "        original = out[s:e]\n",
        "        red = apply_policy(label, original)\n",
        "        if red != original:\n",
        "            out = out[:s] + red + out[e:]\n",
        "    return out\n",
        "\n",
        "# ---------- Load model locally ----------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os, pprint\n",
        "PROJECT_DIR = \"/content/drive/MyDrive/DataShield_AI\"\n",
        "MODEL_DIR   = f\"{PROJECT_DIR}/models/ner-distilbert\"\n",
        "print(\"Exists?\", os.path.isdir(MODEL_DIR))\n",
        "pprint.pp(os.listdir(MODEL_DIR))\n",
        "\n",
        "tok = DistilBertTokenizerFast.from_pretrained(MODEL_DIR, local_files_only=True)\n",
        "mdl = DistilBertForTokenClassification.from_pretrained(MODEL_DIR, local_files_only=True)\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "ner = TokenClassificationPipeline(model=mdl, tokenizer=tok,\n",
        "                                  aggregation_strategy=\"simple\", device=device)\n",
        "\n",
        "samples = [\n",
        "    \"Email me at alice.lee @ example . com or call 415-555-1234. My SSN is 123-45-6789.\",\n",
        "    \"Temp API key: sk_live_1234567890abcdef\",\n",
        "    \"Use 4242-4242-4242-4242 for tests; SSN 123-45-6789 should be blocked.\"\n",
        "]\n",
        "\n",
        "for text in samples:\n",
        "    preds = ner(text)\n",
        "    print(redact_output(text, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxDBxyyVSL49",
        "outputId": "ef9cf5fc-9ef2-4357-a970-b9451052f292"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Exists? True\n",
            "['config.json',\n",
            " 'model.safetensors',\n",
            " 'special_tokens_map.json',\n",
            " 'vocab.txt',\n",
            " 'training_args.bin',\n",
            " 'tokenizer_config.json',\n",
            " 'tokenizer.json',\n",
            " 'labels.json',\n",
            " 'checkpoint-1126',\n",
            " 'checkpoint-1689']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Email me at al***@example.com or call ***-***-***-***-1234 i[PERSON]*[PERSON]**-6***-***-789\n",
            "Temp [PERSON] key: [REDACTED-API][REDACTED-API]E[REDACTED-API][REDACTED-API][REDACTED-API]\n",
            "Use ***-***-***-***-4242 for tests; SS***-***- ***-***-6789 should be blocked.\n"
          ]
        }
      ]
    }
  ]
}